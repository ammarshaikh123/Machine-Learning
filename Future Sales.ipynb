{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv')\nitem_categories = pd.read_csv('../input/item_categories.csv')\nitems = pd.read_csv('../input/items.csv')\nshops = pd.read_csv('../input/shops.csv')\ntrain = pd.read_csv('../input/sales_train.csv', parse_dates=['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns \nimport altair as alt ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train['item_cnt_day'] < 2000]\ntrain = train[train['item_price'] < 300000]\n\nprice_correction = train[(train['shop_id'] == 32) & (train['item_id'] == 2973) & (train['date_block_num'] == 4) & (train['item_price'] > 0)].item_price.median()\ntrain.loc[train['item_price'] < 0, 'item_price'] = price_correction\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['shop_id'] == 0, 'shop_id'] = 57\ntest.loc[test['shop_id'] == 0, 'shop_id'] = 57\n\ntrain.loc[train['shop_id'] == 1, 'shop_id'] = 58\ntest.loc[test['shop_id'] == 1, 'shop_id'] = 58\n\ntrain.loc[train['shop_id'] == 10, 'shop_id'] = 11\ntest.loc[test['shop_id'] == 10, 'shop_id'] = 11\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities = shops['shop_name'].str.split(' ').map(lambda row: row[0])\ncities.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops['city'] = shops['shop_name'].str.split(' ').map(lambda row: row[0])\nshops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\n\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit_transform(shops['city'])\n\nshops['city_label'] = le.fit_transform(shops['city'])\nshops.drop(['shop_name', 'city'], axis = 1, inplace = True)\nshops.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\n\nmain_categories = item_categories['item_category_name'].str.split('-')\nitem_categories['main_category_id'] = main_categories.map(lambda row: row[0].strip())\nitem_categories['main_category_id'] = le.fit_transform(item_categories['main_category_id'])\n\n# Some items don't have sub-categories. For those, we will use the main category as a sub-category\nitem_categories['sub_category_id'] = main_categories.map(lambda row: row[1].strip() if len(row) > 1 else row[0].strip())\nitem_categories['sub_category_id'] = le.fit_transform(item_categories['sub_category_id'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_categories.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train.groupby(['shop_id', 'item_id', 'date_block_num'])['item_cnt_day'].sum().rename('item_cnt_month').reset_index()\ntest.insert(loc=3, column='date_block_num', value=34)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['item_cnt_month'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = x.append(test.drop('ID', axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = pd.merge(new_train, shops, on=['shop_id'], how='left')\nnew_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = pd.merge(new_train, items.drop('item_name', axis = 1), on=['item_id'], how='left')\nnew_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = pd.merge(new_train, item_categories.drop('item_category_name', axis = 1), on=['item_category_id'], how='left')\nnew_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" def generate_lag(train, months, lag_column):\n    for month in months:\n        # Speed up by grabbing only the useful bits\n        train_shift = train[['date_block_num', 'shop_id', 'item_id', lag_column]].copy()\n        train_shift.columns = ['date_block_num', 'shop_id', 'item_id', lag_column+'_lag_'+ str(month)]\n        train_shift['date_block_num'] += month\n        train = pd.merge(train, train_shift, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = generate_lag(new_train, [1,2,3,4,5,6,12], 'item_cnt_month')\nnew_train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = new_train.groupby(['date_block_num', 'item_id'])['item_cnt_month'].mean().rename('item_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'item_id'], how='left')\nnew_train = generate_lag(new_train, [1,2,3,6,12], 'item_month_mean')\nnew_train.drop(['item_month_mean'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = new_train.groupby(['date_block_num', 'shop_id'])['item_cnt_month'].mean().rename('shop_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'shop_id'], how='left')\nnew_train = generate_lag(new_train, [1,2,3,6,12], 'shop_month_mean')\nnew_train.drop(['shop_month_mean'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = new_train.groupby(['date_block_num', 'shop_id', 'item_category_id'])['item_cnt_month'].mean().rename('shop_category_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')\nnew_train = generate_lag(new_train, [1, 2], 'shop_category_month_mean')\nnew_train.drop(['shop_category_month_mean'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = new_train.groupby(['date_block_num', 'main_category_id'])['item_cnt_month'].mean().rename('main_category_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'main_category_id'], how='left')\n\nnew_train = generate_lag(new_train, [1], 'main_category_month_mean')\nnew_train.drop(['main_category_month_mean'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = new_train.groupby(['date_block_num', 'sub_category_id'])['item_cnt_month'].mean().rename('sub_category_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'sub_category_id'], how='left')\n\nnew_train = generate_lag(new_train, [1], 'sub_category_month_mean')\nnew_train.drop(['sub_category_month_mean'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train.tail()","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"         shop_id              ...                sub_category_month_mean_lag_1\n1823318       45              ...                                     1.350698\n1823319       45              ...                                          NaN\n1823320       45              ...                                          NaN\n1823321       45              ...                                          NaN\n1823322       45              ...                                          NaN\n\n[5 rows x 29 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>shop_id</th>\n      <th>item_id</th>\n      <th>date_block_num</th>\n      <th>item_cnt_month</th>\n      <th>city_label</th>\n      <th>item_category_id</th>\n      <th>main_category_id</th>\n      <th>sub_category_id</th>\n      <th>item_cnt_month_lag_1</th>\n      <th>item_cnt_month_lag_2</th>\n      <th>item_cnt_month_lag_3</th>\n      <th>item_cnt_month_lag_4</th>\n      <th>item_cnt_month_lag_5</th>\n      <th>item_cnt_month_lag_6</th>\n      <th>item_cnt_month_lag_12</th>\n      <th>item_month_mean_lag_1</th>\n      <th>item_month_mean_lag_2</th>\n      <th>item_month_mean_lag_3</th>\n      <th>item_month_mean_lag_6</th>\n      <th>item_month_mean_lag_12</th>\n      <th>shop_month_mean_lag_1</th>\n      <th>shop_month_mean_lag_2</th>\n      <th>shop_month_mean_lag_3</th>\n      <th>shop_month_mean_lag_6</th>\n      <th>shop_month_mean_lag_12</th>\n      <th>shop_category_month_mean_lag_1</th>\n      <th>shop_category_month_mean_lag_2</th>\n      <th>main_category_month_mean_lag_1</th>\n      <th>sub_category_month_mean_lag_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1823318</th>\n      <td>45</td>\n      <td>18454</td>\n      <td>34</td>\n      <td>0.0</td>\n      <td>20</td>\n      <td>55</td>\n      <td>13</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.506438</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.197183</td>\n      <td>NaN</td>\n      <td>1.329302</td>\n      <td>1.350698</td>\n    </tr>\n    <tr>\n      <th>1823319</th>\n      <td>45</td>\n      <td>16188</td>\n      <td>34</td>\n      <td>0.0</td>\n      <td>20</td>\n      <td>64</td>\n      <td>14</td>\n      <td>42</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1823320</th>\n      <td>45</td>\n      <td>15757</td>\n      <td>34</td>\n      <td>0.0</td>\n      <td>20</td>\n      <td>55</td>\n      <td>13</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1823321</th>\n      <td>45</td>\n      <td>19648</td>\n      <td>34</td>\n      <td>0.0</td>\n      <td>20</td>\n      <td>40</td>\n      <td>11</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1823322</th>\n      <td>45</td>\n      <td>969</td>\n      <td>34</td>\n      <td>0.0</td>\n      <td>20</td>\n      <td>37</td>\n      <td>11</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport xgboost as xgb\ndef xgtrain():\n    regressor = xgb.XGBRegressor(n_estimators = 5000,\n                                 learning_rate = 0.01,\n                                 max_depth = 10,\n                                 subsample = 0.5,\n                                 colsample_bytree = 0.5)\n    \n    regressor_ = regressor.fit(new_train[new_train.date_block_num < 33].drop(['item_cnt_month'], axis=1).values, \n                               new_train[new_train.date_block_num < 33]['item_cnt_month'].values, \n                               eval_metric = 'rmse', \n                               eval_set = [(new_train[new_train.date_block_num < 33].drop(['item_cnt_month'], axis=1).values, \n                                            new_train[new_train.date_block_num < 33]['item_cnt_month'].values), \n                                           (new_train[new_train.date_block_num == 33].drop(['item_cnt_month'], axis=1).values, \n                                            new_train[new_train.date_block_num == 33]['item_cnt_month'].values)\n                                          ], \n                               verbose=True,\n                               early_stopping_rounds = 50,\n                              )\n    return regressor_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nregressor_ = xgtrain()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}